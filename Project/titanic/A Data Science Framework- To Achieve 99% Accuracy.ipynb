{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '7'> Table of Contents </font>\n",
    "\n",
    " - Chapter 1 - How a Data Scientist Beat the Odds\n",
    " - Chapter 2 - A Data Science Framework \n",
    " - Chaptrer 3 - Step 1: Define the Problem and Step 2: Gather the data \n",
    " - Chapter 4 - Step 3: Prepare Data for Consumption\n",
    " - Chapter 5 - The 4 C's Data Cleanning - Correcting, Completing, Creating, and Converting \n",
    " - Chapter 6 - Step 4: Perform EDA with Stats\n",
    " - Chapter 7 - Step 5: Model Data \n",
    " - Chapter 8 - Evaluate Model Performance \n",
    " - Chapter 9 - Tune Model With Hyper-Parameters\n",
    " - Chapter 10 - Tune Model with Feature Selection\n",
    " - Chapter 11 - Step 6: Validate and Implement \n",
    " - Chapter 12 - Conclusion and Step 7: Optimize and Strategize \n",
    " - Change Log\n",
    " - Credits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '4'> How a Data Scientist Beat the Odds </font>\n",
    "\n",
    "It's the classical problem, predict the outcome of a binary event. In laymen terms this means, it either occurred or did not occur. For example, you won or did not win, you passed the test or did not pass the test, you were accepted or not accepted, and you get the point. A common business application is churn or customer retention. Another popular use case is, healthcare's mortality rate or survival analysis. Binary events create an interesting dynamic, because we know statistically, a random guess should achieve a 50% accuracy rate, without creating one single algorithm or writing one single line of code. However, just like autocorrect spellcheck technology, sometimes we humans can be too smart for our own good and actually underperform a coin flip. In this kernel, I use Kaggle's Getting Started Competition, Titanic: Machine Learning from Disaster, to walk the reader through, how-to use the data science framework to beat the odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> **A Data Science Framework** </font>\n",
    "\n",
    "1. **Define the Problem**: If data science, big data, machine learning, predictive analytics, business intellidence, or any other buzzword is the solution, then what is the problem?. As the saying goes, don't put the cart before the horse. `Problems before requirements, requirements before solutions, solutions before design, and design before technology*`Too often we are quick to jump on the new shiny technology, tool, or algorithm before determining the actual problem we are trying to solve.\n",
    "\n",
    "2. **Gather the Data**: John Naisbitt wrote in his book, we are 'drowning in data', yet staving for knowledge. So, chances are, the datasets already exist somewhere, in some format. It may be external or internal, structured or unstructered, static or streamed, objective or subjective. As the saying goes, you don't have to reinvent the wheel, you just have to know where to find it. In the next step, we will worry about transforming 'dirty data' to 'clean data'.\n",
    "\n",
    "3. **Prepare Data for Consumption**: This step is often referred to as data wrangling, a required process to turn 'wild' data into 'manageable' data. Data wrangling includes implementing data architectures for storage and processing, developing data governance standards for quality and control,. data extraction, and data cleaning to identify aberrant, missing, or outlier data points. \n",
    "\n",
    "4. **Perform Exploratory Analysis**: Anybody who has ever worked with data knows, garbage-in, garbage-out (GIGO). Therefore, it is important to deploy descriptive and graphical statistics to look for potential problems, patterns, classifications, correlations and comparisons in the dataset. In addition, data categorization (qualitative and quantitative) is also important to understand and select the correct hypothesis test or data model/\n",
    "\n",
    "5. **Model Data**: Like descriptive and inferential stats, data modeling can either suummarize the data or predict future outcomes. Your dataset and expected results, will determine the algorithms available for use. It's important to remember, algorithms are tools and not magiccal wands or silver bullets. You must still be the master craft that select the right tool for the job. An analogy would be asking someone to hand you a Philip screwdriver, and they hand you a flathead screwdriver or worst a hammer. At best, it shows a complete lack of understanding. At worst, it makes completing the project impossible. The same is true in data modeling. The wrong model can lead to poor performance at best and wrong conclusion (that;s used as actionable intelligence) at worst.\n",
    "\n",
    "6. **Validate and Implement Data Model**: After you've trained your model based on subset of your data, it's time to test your model. This helps ensure you haven't overfit your model or made it so specific to the selected subset, that it does not accurately fit another subset from the same dataset. In this step, we determine if our model overfit generalize, or underfit our dataset. \n",
    "\n",
    "7. **Optimize and Strategize**: This is the 'bionic man' step, where you iterate back through the process to make it bettter, stronger and faster than it was before. As a data scientist, your strategy should be to outsource developer operations and application plumbing, so you more time to focus on recommendations and design. Once you're able to package your ideas, this becomes your 'currency exchange' rate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5'> **Step 1: Define the Problem** </font>\n",
    "\n",
    "For this project, the problem statement is given to us a golden plater, develop an algorithm to predict the survival outcome of passengers on the Titanic.\n",
    "\n",
    "Project Summary: The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "Practice Skills\n",
    "\n",
    "Binary classification\n",
    "Python and R basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5'> **Step 2: Gather the Data** </font>\n",
    "\n",
    "The dataset is also given to us on a golden plater with test and train data at Kaggle's Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5'> **Step 3: Prepare Data for Consumption** </font>\n",
    "\n",
    "Since step 2 was provided to us on a golden plater, so is step 3. Therefore, normal processes in data wrangling, such as data architecture, governance, and extraction are out of scope. Thus, only data cleaning is in scope.\n",
    "\n",
    "<font size='3'> **3.1: Import Libraries** </font>\n",
    "\n",
    "The following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks. The idea is why write ten lines of code, when you can write one line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 1.0.1\n",
      "matplotlib version: 3.1.3\n",
      "NumPy version : 1.18.1\n",
      "SCiPy version: 1.4.1\n",
      "IPython version:7.12.0\n",
      "scikit-learn version: 0.22.1\n",
      "_________________________\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed \n",
    "# It is defined by  the kaggle/python docker image \n",
    "\n",
    "# Load packages \n",
    "\n",
    "import sys # access to sytem parameters \n",
    "print('Python version: {}'.format(sys.version))\n",
    "\n",
    "import pandas as pd \n",
    "print('pandas version: {}'.format(pd.__version__))\n",
    "\n",
    "import matplotlib \n",
    "print('matplotlib version: {}'.format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np \n",
    "print('NumPy version : {}'.format(np.__version__))\n",
    "\n",
    "import scipy as sp \n",
    "print('SCiPy version: {}'.format(sp.__version__))\n",
    "\n",
    "import IPython\n",
    "from IPython import display #Pretty printing of dataframes in Jupyter notebook \n",
    "print('IPython version:{}'.format(IPython.__version__))\n",
    "\n",
    "import sklearn # collection of machine learning algorithms\n",
    "print('scikit-learn version: {}'.format(sklearn.__version__))\n",
    "\n",
    "# misc libraries \n",
    "import random \n",
    "import time \n",
    "\n",
    "# ignore warnings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('_'*25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'> **3.11: Load Data Modelling Libraries** </font>\n",
    "\n",
    "We will use the popular scikit-learn library to develop our machine learning algorithms. In sklearn, algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the matplotlib and seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Model ALgorithms \n",
    "\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "\n",
    "#Common Model Helpers \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder \n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics \n",
    "\n",
    "#Visualization \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pylab as pylab \n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "# Configure VisualizationDefaults \n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser \n",
    "%matplotlib inline\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize']=12,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> **Meet and Greet Data** </font> \n",
    "\n",
    "This is the meet and greet step. Get to know your data by first name and leanr alittle bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables), what's it goal in lfe (dependent/target variable(s)). Think of it like a first date, before you jumpin and start poking it in the bedroom\n",
    "\n",
    "To begin this step, we first import our data. Next we use the info() and sample() function, to get a quick and dirty overview of variable datatypes (qualitative vs quantitative).\n",
    "\n",
    "  1. The Survived variable is our outcome or dependent variable. It is abinary nomial datatype of 1  for survived and 0 for did not survive. All other variables are potential predictor or independent variables. **It's important to note, more predictor variables do not make better model, but the right variables**\n",
    "  2. The PassengerID and Ticket varrables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis \n",
    "  3. The Pclass variable is an ordinal datatype for the ticket class, a proxy for socio--economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n",
    "  4. The Name variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like dotor or master. Since these variable already exist, we'll make use of it to see if title, like master, makes a difference.\n",
    "  5. The Sex and Embarked variables are a nominal datatype. They will be converted to dummy variables for mathematical calculations \n",
    "  6. The Age and Fare variable are continuous quantitative datatypes.\n",
    "  7. The SibSp represents number of related siblings/spouse aboard and Parch represents number of related parents.children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and is alone variable.\n",
    "  8. The Cabin variable is a nominal datatype that can be used in feature engineering for approximate position on ship when the incident occurred and SES from deck levels. However since there are many null values, it does not add value and thus is excluded from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>811</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alexander, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3474</td>\n",
       "      <td>7.8875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Van der hoef, Mr. Wyckoff</td>\n",
       "      <td>male</td>\n",
       "      <td>61.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111240</td>\n",
       "      <td>33.5000</td>\n",
       "      <td>B19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sedgwick, Mr. Charles Frederick Waddington</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244361</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aubart, Mme. Leontine Pauline</td>\n",
       "      <td>female</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17477</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>B35</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>802</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mrs. Harvey (Charlotte Annie Tate)</td>\n",
       "      <td>female</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Landergren, Miss. Aurora Adelia</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C 7077</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "810          811         0       3   \n",
       "170          171         0       1   \n",
       "876          877         0       3   \n",
       "343          344         0       2   \n",
       "369          370         1       1   \n",
       "801          802         1       2   \n",
       "376          377         1       3   \n",
       "862          863         1       1   \n",
       "305          306         1       1   \n",
       "866          867         1       2   \n",
       "\n",
       "                                                  Name     Sex    Age  SibSp  \\\n",
       "810                             Alexander, Mr. William    male  26.00      0   \n",
       "170                          Van der hoef, Mr. Wyckoff    male  61.00      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.00      0   \n",
       "343         Sedgwick, Mr. Charles Frederick Waddington    male  25.00      0   \n",
       "369                      Aubart, Mme. Leontine Pauline  female  24.00      0   \n",
       "801        Collyer, Mrs. Harvey (Charlotte Annie Tate)  female  31.00      1   \n",
       "376                    Landergren, Miss. Aurora Adelia  female  22.00      0   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.00      0   \n",
       "305                     Allison, Master. Hudson Trevor    male   0.92      1   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.00      1   \n",
       "\n",
       "     Parch         Ticket      Fare    Cabin Embarked  \n",
       "810      0           3474    7.8875      NaN        S  \n",
       "170      0         111240   33.5000      B19        S  \n",
       "876      0           7534    9.8458      NaN        S  \n",
       "343      0         244361   13.0000      NaN        S  \n",
       "369      0       PC 17477   69.3000      B35        C  \n",
       "801      1     C.A. 31921   26.2500      NaN        S  \n",
       "376      0         C 7077    7.2500      NaN        S  \n",
       "862      0          17466   25.9292      D17        S  \n",
       "305      2         113781  151.5500  C22 C26        S  \n",
       "866      0  SC/PARIS 2149   13.8583      NaN        C  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data \n",
    "\n",
    "data_raw = pd.read_csv('train.csv')\n",
    "\n",
    "# dataset should be broken into 3 splits: train, test, and(final) validation \n",
    "# the test file provided is the validation file for competition submission \n",
    "\n",
    "data_val = pd.read_csv('test.csv')\n",
    "# to play with our data we'll create a copy \n",
    "data1 = data_raw.copy(deep = True)\n",
    "\n",
    "#however passing by reference is convenienct, because we can clean both datasets at one \n",
    "\n",
    "data_cleaner = [data1, data_val]\n",
    "\n",
    "# preview data \n",
    "print(data_raw.info())\n",
    "data_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> **THe 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting** </font>\n",
    "\n",
    "In this stage, we will clean our data by\n",
    "\n",
    " - 1) Correcting aberrant values and outliers \n",
    " - 2) completing missing information \n",
    " - 3) creating new features for analysis\n",
    " - 4) converting fields to the correct format for calculations and presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Correcting**: Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs. In addition, we see we may have potential outliers in age and fare. However, since they are reasonable values, we will wait until after we complete our EDA to determine if we should include or exclude the dataset. It should be noted, that if they were unreasonable values, for example age = 800 instead of 80, then it's probably a safe decision to fix now. However, we want to use caution when we modify data from its original value, because it may be neccesary to create an  accurate model.\n",
    "\n",
    "2. **Completing**: There are null values or missing data in the age, cabin, and emabrked field. Missing values can be bad, because some algorithms don't know how to handle null values and will fail. While others, like decision trees, can handle null values. Thus, it's important to fix before we start modeling, because we will compare and contrast several models. There are two common methods, either delete the record or populate the missing value using a reasonable input. It is not recommended to delete the record, especially a large percentage of records, unless it tryly represents an incomplete record. Instead, it's best to impute missing values. A basic methodolodogy for qualitative data is impute using mode. A basic methodolody for quantitative d√¢t is impute using mean, median, or mean + randomized standard deviation. An intermediate methodology is to use the basic methodology based on specific criteria; like the average age by class or embark port by fare and SES. There are more comple methodologies, however before deploying, it shouyld be compared to the base model to determine if complexity tryly adds value. For this dataset, age will be imputed with the median, the cabin attribute will be dropped, and embark will be imputed with mode. Subsequrnt model iterations may modify this decision to determine if it improves the model's accuracy.\n",
    "\n",
    "3. **Creating**: Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. For this dataset, we will create a title feature to determine if it improves the model's accuracy.\n",
    "\n",
    "4. **Converting**: Last, but certainly not least, we'll deal with formating. There are no date or currency formats, but datatype formats. Our categorical data imported as objects, which makes it difficult for mathematical calculations. For this dataset, we will convert object datatypes to categorical dummy variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "____________________________________________________________________________________________________\n",
      "Test/Validation columns with null values:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asplund, Miss. Lillian Gertrud</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                            Name  \\\n",
       "count    891.000000  891.000000  891.000000                             891   \n",
       "unique          NaN         NaN         NaN                             891   \n",
       "top             NaN         NaN         NaN  Asplund, Miss. Lillian Gertrud   \n",
       "freq            NaN         NaN         NaN                               1   \n",
       "mean     446.000000    0.383838    2.308642                             NaN   \n",
       "std      257.353842    0.486592    0.836071                             NaN   \n",
       "min        1.000000    0.000000    1.000000                             NaN   \n",
       "25%      223.500000    0.000000    2.000000                             NaN   \n",
       "50%      446.000000    0.000000    3.000000                             NaN   \n",
       "75%      668.500000    1.000000    3.000000                             NaN   \n",
       "max      891.000000    1.000000    3.000000                             NaN   \n",
       "\n",
       "         Sex         Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
       "count    891  714.000000  891.000000  891.000000     891  891.000000      204   \n",
       "unique     2         NaN         NaN         NaN     681         NaN      147   \n",
       "top     male         NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq     577         NaN         NaN         NaN       7         NaN        4   \n",
       "mean     NaN   29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      NaN   14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min      NaN    0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      NaN   20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      NaN   28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      NaN   38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      NaN   80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train columns with null values:\\n', data1.isnull().sum())\n",
    "print('_'*100)\n",
    "\n",
    "print('Test/Validation columns with null values:\\n', data_val.isnull().sum())\n",
    "print('_'*100)\n",
    "\n",
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size ='5'> **3.22 Clean Data** </font>\n",
    "\n",
    "Now that we know what to clean, lets excecute our code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer Documentation:**\n",
    "\n",
    " - pandas.DataFrame\n",
    " - pandas.DataFrame.info\n",
    " - pandas.DataFrame.describe\n",
    " - Indexing and Selecting Data \n",
    " - pandas.isnull\n",
    " - pandas.DataFrame.sum\n",
    " - pandas.DataFrame.mode\n",
    " - pandas.DataFrame.copy\n",
    " - pandas.DataFrame.fillna\n",
    " - pandas.DataFrame.drop\n",
    " - pandas.Series.value_counts\n",
    " - pandas.DataFrame.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "____________________________________________________________________________________________________\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###COMPLETING:complete or delete missing values in train and test /validation dataset \n",
    "\n",
    "for dataset in data_cleaner:\n",
    "    #complete missing age with median\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
    "    \n",
    "    # complete embarked with mode \n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "    \n",
    "    # complete missing fare with median \n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace= True)\n",
    "    \n",
    "#delete the cabin feature/ column and others previously stated to exclude in train dataset \n",
    "drop_column = ['PassengerId', 'Cabin', 'Ticket']\n",
    "data1.drop(drop_column, axis=1, inplace = True)\n",
    "\n",
    "print(data1.isnull().sum())\n",
    "print('_'*100)\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   Survived    891 non-null    int64   \n",
      " 1   Pclass      891 non-null    int64   \n",
      " 2   Name        891 non-null    object  \n",
      " 3   Sex         891 non-null    object  \n",
      " 4   Age         891 non-null    float64 \n",
      " 5   SibSp       891 non-null    int64   \n",
      " 6   Parch       891 non-null    int64   \n",
      " 7   Fare        891 non-null    float64 \n",
      " 8   Embarked    891 non-null    object  \n",
      " 9   FamilySize  891 non-null    int64   \n",
      " 10  IsAlone     891 non-null    int64   \n",
      " 11  Title       891 non-null    object  \n",
      " 12  FareBin     891 non-null    category\n",
      " 13  AgeBin      891 non-null    category\n",
      "dtypes: category(2), float64(2), int64(6), object(4)\n",
      "memory usage: 85.8+ KB\n",
      "____________________________________________________________________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  418 non-null    int64   \n",
      " 1   Pclass       418 non-null    int64   \n",
      " 2   Name         418 non-null    object  \n",
      " 3   Sex          418 non-null    object  \n",
      " 4   Age          418 non-null    float64 \n",
      " 5   SibSp        418 non-null    int64   \n",
      " 6   Parch        418 non-null    int64   \n",
      " 7   Ticket       418 non-null    object  \n",
      " 8   Fare         418 non-null    float64 \n",
      " 9   Cabin        91 non-null     object  \n",
      " 10  Embarked     418 non-null    object  \n",
      " 11  FamilySize   418 non-null    int64   \n",
      " 12  IsAlone      418 non-null    int64   \n",
      " 13  Title        418 non-null    object  \n",
      " 14  FareBin      418 non-null    category\n",
      " 15  AgeBin       418 non-null    category\n",
      "dtypes: category(2), float64(2), int64(6), object(6)\n",
      "memory usage: 47.1+ KB\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chambers, Mrs. Norman Campbell (Bertha Griggs)</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Padro y Manent, Mr. Julian</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Leary, Miss. Hanora \"Norah\"</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Miss. Eleanor Ileen</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Stoytcheff, Mr. Ilia</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sagesser, Mlle. Emma</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Misc</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Gee, Mr. Arthur H</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petterson, Mr. Johan Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Risien, Mr. Samuel Beard</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Carbines, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                            Name     Sex  \\\n",
       "809         1       1  Chambers, Mrs. Norman Campbell (Bertha Griggs)  female   \n",
       "547         1       2                      Padro y Manent, Mr. Julian    male   \n",
       "653         1       3                   O'Leary, Miss. Hanora \"Norah\"  female   \n",
       "172         1       3                    Johnson, Miss. Eleanor Ileen  female   \n",
       "566         0       3                            Stoytcheff, Mr. Ilia    male   \n",
       "641         1       1                            Sagesser, Mlle. Emma  female   \n",
       "462         0       1                               Gee, Mr. Arthur H    male   \n",
       "442         0       3                       Petterson, Mr. Johan Emil    male   \n",
       "538         0       3                        Risien, Mr. Samuel Beard    male   \n",
       "191         0       2                           Carbines, Mr. William    male   \n",
       "\n",
       "      Age  SibSp  Parch     Fare Embarked  FamilySize  IsAlone  Title  \\\n",
       "809  33.0      1      0  53.1000        S           2        0    Mrs   \n",
       "547  28.0      0      0  13.8625        C           1        1     Mr   \n",
       "653  28.0      0      0   7.8292        Q           1        1   Miss   \n",
       "172   1.0      1      1  11.1333        S           3        0   Miss   \n",
       "566  19.0      0      0   7.8958        S           1        1     Mr   \n",
       "641  24.0      0      0  69.3000        C           1        1   Misc   \n",
       "462  47.0      0      0  38.5000        S           1        1     Mr   \n",
       "442  25.0      1      0   7.7750        S           2        0     Mr   \n",
       "538  28.0      0      0  14.5000        S           1        1     Mr   \n",
       "191  19.0      0      0  13.0000        S           1        1     Mr   \n",
       "\n",
       "             FareBin         AgeBin  \n",
       "809  (31.0, 512.329]   (32.0, 48.0]  \n",
       "547   (7.91, 14.454]   (16.0, 32.0]  \n",
       "653   (-0.001, 7.91]   (16.0, 32.0]  \n",
       "172   (7.91, 14.454]  (-0.08, 16.0]  \n",
       "566   (-0.001, 7.91]   (16.0, 32.0]  \n",
       "641  (31.0, 512.329]   (16.0, 32.0]  \n",
       "462  (31.0, 512.329]   (32.0, 48.0]  \n",
       "442   (-0.001, 7.91]   (16.0, 32.0]  \n",
       "538   (14.454, 31.0]   (16.0, 32.0]  \n",
       "191   (7.91, 14.454]   (16.0, 32.0]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###CREATE: Feature Engineering for train and test/validation dataset \n",
    "\n",
    "for dataset in data_cleaner:\n",
    "    #Discrete variables\n",
    "    dataset['FamilySize'] = dataset['SibSp']+ dataset['Parch'] + 1 \n",
    "    dataset['IsAlone'] = 1 \n",
    "    dataset['IsAlone'].loc[dataset['FamilySize']>1] = 0\n",
    "    dataset['Title'] = dataset['Name'].str.split(',', expand = True)[1].str.split('.', expand=True)[0]\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n",
    "\n",
    "\n",
    "stat_min = 10 \n",
    "title_names = (data1['Title'].value_counts() < stat_min)\n",
    "\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "\n",
    "#preview \n",
    "data1.info()\n",
    "print('_'*100)\n",
    "data_val.info()\n",
    "print('_'*100)\n",
    "data1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> **3.23 Convert Formats** </font>\n",
    "\n",
    "We will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions.\n",
    "\n",
    "In this step, we will also define our x (independent/features/explanatory/predictor/etc.) and y (dependent/target/response/etc.) variables for data modeling.\n",
    "\n",
    "**Developer Documentation** \n",
    "\n",
    "- Categorical Encoding \n",
    "- Sklearn LabelEncoder \n",
    "- Sklearn OneHotEncoder\n",
    "- Pandas Categorical dtype\n",
    "- pandas.get_dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y: ['Survived', 'Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
      "\n",
      "Bin X Y:  ['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_code'] \n",
      "\n",
      "Dummy X Y:  ['Survived', 'Pclass', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_ Master', 'Title_ Miss', 'Title_ Mr', 'Title_ Mrs', 'Title_Misc'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_ Master</th>\n",
       "      <th>Title_ Miss</th>\n",
       "      <th>Title_ Mr</th>\n",
       "      <th>Title_ Mrs</th>\n",
       "      <th>Title_Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch   Age     Fare  FamilySize  IsAlone  Sex_female  \\\n",
       "0       3      1      0  22.0   7.2500           2        0           0   \n",
       "1       1      1      0  38.0  71.2833           2        0           1   \n",
       "2       3      0      0  26.0   7.9250           1        1           1   \n",
       "3       1      1      0  35.0  53.1000           2        0           1   \n",
       "4       3      0      0  35.0   8.0500           1        1           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_ Master  Title_ Miss  \\\n",
       "0         1           0           0           1              0            0   \n",
       "1         0           1           0           0              0            0   \n",
       "2         0           0           0           1              0            1   \n",
       "3         0           0           0           1              0            0   \n",
       "4         1           0           0           1              0            0   \n",
       "\n",
       "   Title_ Mr  Title_ Mrs  Title_Misc  \n",
       "0          1           0           0  \n",
       "1          0           1           0  \n",
       "2          0           0           0  \n",
       "3          0           1           0  \n",
       "4          1           0           0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONVERT: convert objects to category using Label Encoder for train and test/ validation dataset\n",
    "\n",
    "#code categorical data \n",
    "\n",
    "label = LabelEncoder() \n",
    "for dataset in data_cleaner:\n",
    "    dataset['Sex_Code']=label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n",
    "    \n",
    "# define  y variable aka target/outcome \n",
    "\n",
    "Target = ['Survived']\n",
    "\n",
    "# define x variables for original features aka feature selection \n",
    "data1_x = ['Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
    "data1_x_calc = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare'] \n",
    "data1_xy = Target + data1_x \n",
    "print('Original X Y:', data1_xy, '\\n')\n",
    "\n",
    "# define x variables for original w/bin features to remove continuous variables \n",
    "\n",
    "data1_x_bin = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_code']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')\n",
    "\n",
    "# define x and y variables for dummy features original \n",
    "\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')\n",
    "\n",
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size ='5'> **3.24 Da-Double Check Cleaned Data** </font>\n",
    "\n",
    "Now that we've cleaned our data, let's do a discount da-double check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values: \n",
      " Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare             0\n",
      "Embarked         0\n",
      "FamilySize       0\n",
      "IsAlone          0\n",
      "Title            0\n",
      "FareBin          0\n",
      "AgeBin           0\n",
      "Sex_Code         0\n",
      "Embarked_Code    0\n",
      "Title_Code       0\n",
      "AgeBin_Code      0\n",
      "FareBin_Code     0\n",
      "dtype: int64\n",
      "----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   Survived       891 non-null    int64   \n",
      " 1   Pclass         891 non-null    int64   \n",
      " 2   Name           891 non-null    object  \n",
      " 3   Sex            891 non-null    object  \n",
      " 4   Age            891 non-null    float64 \n",
      " 5   SibSp          891 non-null    int64   \n",
      " 6   Parch          891 non-null    int64   \n",
      " 7   Fare           891 non-null    float64 \n",
      " 8   Embarked       891 non-null    object  \n",
      " 9   FamilySize     891 non-null    int64   \n",
      " 10  IsAlone        891 non-null    int64   \n",
      " 11  Title          891 non-null    object  \n",
      " 12  FareBin        891 non-null    category\n",
      " 13  AgeBin         891 non-null    category\n",
      " 14  Sex_Code       891 non-null    int32   \n",
      " 15  Embarked_Code  891 non-null    int32   \n",
      " 16  Title_Code     891 non-null    int32   \n",
      " 17  AgeBin_Code    891 non-null    int32   \n",
      " 18  FareBin_Code   891 non-null    int32   \n",
      "dtypes: category(2), float64(2), int32(5), int64(6), object(4)\n",
      "memory usage: 103.3+ KB\n",
      "None\n",
      "----------\n",
      "Test/Validation columns with null values: \n",
      " PassengerId        0\n",
      "Pclass             0\n",
      "Name               0\n",
      "Sex                0\n",
      "Age                0\n",
      "SibSp              0\n",
      "Parch              0\n",
      "Ticket             0\n",
      "Fare               0\n",
      "Cabin            327\n",
      "Embarked           0\n",
      "FamilySize         0\n",
      "IsAlone            0\n",
      "Title              0\n",
      "FareBin            0\n",
      "AgeBin             0\n",
      "Sex_Code           0\n",
      "Embarked_Code      0\n",
      "Title_Code         0\n",
      "AgeBin_Code        0\n",
      "FareBin_Code       0\n",
      "dtype: int64\n",
      "----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   PassengerId    418 non-null    int64   \n",
      " 1   Pclass         418 non-null    int64   \n",
      " 2   Name           418 non-null    object  \n",
      " 3   Sex            418 non-null    object  \n",
      " 4   Age            418 non-null    float64 \n",
      " 5   SibSp          418 non-null    int64   \n",
      " 6   Parch          418 non-null    int64   \n",
      " 7   Ticket         418 non-null    object  \n",
      " 8   Fare           418 non-null    float64 \n",
      " 9   Cabin          91 non-null     object  \n",
      " 10  Embarked       418 non-null    object  \n",
      " 11  FamilySize     418 non-null    int64   \n",
      " 12  IsAlone        418 non-null    int64   \n",
      " 13  Title          418 non-null    object  \n",
      " 14  FareBin        418 non-null    category\n",
      " 15  AgeBin         418 non-null    category\n",
      " 16  Sex_Code       418 non-null    int32   \n",
      " 17  Embarked_Code  418 non-null    int32   \n",
      " 18  Title_Code     418 non-null    int32   \n",
      " 19  AgeBin_Code    418 non-null    int32   \n",
      " 20  FareBin_Code   418 non-null    int32   \n",
      "dtypes: category(2), float64(2), int32(5), int64(6), object(6)\n",
      "memory usage: 55.3+ KB\n",
      "None\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asplund, Miss. Lillian Gertrud</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                            Name  \\\n",
       "count    891.000000  891.000000  891.000000                             891   \n",
       "unique          NaN         NaN         NaN                             891   \n",
       "top             NaN         NaN         NaN  Asplund, Miss. Lillian Gertrud   \n",
       "freq            NaN         NaN         NaN                               1   \n",
       "mean     446.000000    0.383838    2.308642                             NaN   \n",
       "std      257.353842    0.486592    0.836071                             NaN   \n",
       "min        1.000000    0.000000    1.000000                             NaN   \n",
       "25%      223.500000    0.000000    2.000000                             NaN   \n",
       "50%      446.000000    0.000000    3.000000                             NaN   \n",
       "75%      668.500000    1.000000    3.000000                             NaN   \n",
       "max      891.000000    1.000000    3.000000                             NaN   \n",
       "\n",
       "         Sex         Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
       "count    891  714.000000  891.000000  891.000000     891  891.000000      204   \n",
       "unique     2         NaN         NaN         NaN     681         NaN      147   \n",
       "top     male         NaN         NaN         NaN  347082         NaN  B96 B98   \n",
       "freq     577         NaN         NaN         NaN       7         NaN        4   \n",
       "mean     NaN   29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
       "std      NaN   14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
       "min      NaN    0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
       "25%      NaN   20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
       "50%      NaN   28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
       "75%      NaN   38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
       "max      NaN   80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train columns with null values: \\n', data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print (data1.info())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Test/Validation columns with null values: \\n', data_val.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print (data_val.info())\n",
    "print(\"-\"*10)\n",
    "\n",
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = '5'> **3.25 Split Training and Testing Data** </font>\n",
    "\n",
    "As mentioned previously, the test file provided is really validation data for competition submission. So, we will use sklearn function to split the training data in two datasets; 75/25 split. This is important, so we don't overfit our model. Meaning, the algorithm is so specific to a given subset, it cannot accurately generalize another subset, from the same dataset. It's important our algorithm has not seen the subset we will use to test, so it doesn't \"cheat\" by memorizing the answers. We will use sklearn's train_test_split function. In later sections we will also use sklearn's cross validation functions, that splits our dataset into train and test for data modeling comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
